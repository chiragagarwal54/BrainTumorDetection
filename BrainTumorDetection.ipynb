{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyJvn1Z8NyO2"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMd_Vus4Npvn"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1C5uwn0N6b4"
      },
      "outputs": [],
      "source": [
        "Dataset = '/content/drive/MyDrive/BRAIN MRI DATASET'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kKOmpojN9v2"
      },
      "outputs": [],
      "source": [
        "#Importing libraries\n",
        "%matplotlib inline\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, random, shutil\n",
        "import tensorflow as tf\n",
        "import seaborn\n",
        "from glob import glob\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import preprocessing, layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras_preprocessing import image\n",
        "import PIL\n",
        "import cv2\n",
        "from keras.constraints import maxnorm\n",
        "from keras.models import Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.models import load_model\n",
        "from keras.layers import GlobalAveragePooling2D, Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten, Activation\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from cv2 import cv2\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, ZeroPadding2D\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from numpy import array \n",
        "from keras import regularizers\n",
        "from keras import optimizers\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "import pathlib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5m0C6qMOLF1"
      },
      "outputs": [],
      "source": [
        "def getTotalImages():\n",
        "\n",
        "  total_images = 0\n",
        "  for c in ['G','M','N','P']:\n",
        "    total_images += len(os.listdir(os.path.join(Dataset, c)))\n",
        "  # print('Total:', total_images)\n",
        "  return total_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3av_vR92PK69"
      },
      "outputs": [],
      "source": [
        "def defineTumourLabels():\n",
        "  data_dir = \"\"\n",
        "  data_dir = pathlib.Path(Dataset)\n",
        "  Tumor_images_dict= {}\n",
        "  Tumor_labels_dict = {}\n",
        "  Tumor_images_dict= {\n",
        "      'G': list(data_dir.glob('G/*')),\n",
        "      'M': list(data_dir.glob('M/*')),\n",
        "      'N': list(data_dir.glob('N/*')),  \n",
        "      'P': list(data_dir.glob('P/*'))\n",
        "  }\n",
        "  Tumor_labels_dict = {\n",
        "      'G':0,\n",
        "      'M': 1,\n",
        "      'N': 2,\n",
        "      'P': 3,\n",
        "  }\n",
        "  return Tumor_images_dict,Tumor_labels_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYuadpolPLSp"
      },
      "outputs": [],
      "source": [
        "def preProcess(Tumor_images_dict,Tumor_labels_dict):\n",
        "  print(\"\\n Enter the Dataset Size\")\n",
        "  Dataset_Size = input()\n",
        "  Dataset_Size = int(Dataset_Size)\n",
        "  X, y = [],[]\n",
        "\n",
        "  for Tumor_name, images in Tumor_images_dict.items():\n",
        "      for image in images[0:Dataset_Size]:\n",
        "          img= cv2.imread(str(image))\n",
        "          im_color = cv2.applyColorMap(img, cv2.COLORMAP_JET)\n",
        "          resized_img = cv2.resize(im_color,(180,180))\n",
        "          X.append(resized_img)\n",
        "          y.append(Tumor_labels_dict[Tumor_name])\n",
        "  return X,y     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3hBX772Q4DM"
      },
      "outputs": [],
      "source": [
        "def split(X,y):\n",
        "  X =  np.array(X)\n",
        "  y = np.array(y)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0) #input 2\n",
        "  X_train_scaled = X_train / 255\n",
        "  X_test_scaled = X_test / 255\n",
        "  return X_train_scaled,X_test_scaled,y_train,y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uFlIJ0qR_XX"
      },
      "outputs": [],
      "source": [
        "def struct_model():\n",
        "    num_classes = 4;\n",
        "    model = Sequential([\n",
        "    #input 3             \n",
        "    layers.Conv2D(275,(3,3), padding='same', activation='relu', input_shape=(180,180,3)),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "    layers.Dropout(0.2),\n",
        "\n",
        "    layers.Conv2D(250,(3,3), padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "    layers.Dropout(0.2),\n",
        "\n",
        "    layers.Conv2D(225,(3,3), padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "    layers.Dropout(0.2),\n",
        "    \n",
        "    layers.Flatten(),\n",
        "    layers.Dense(100, activation='relu'),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Dense(50, activation='relu'),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Dense(num_classes,activation='softmax')  \n",
        "])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Validation_Process(model,X_test_scaled, y_test):\n",
        "  show_validation_accuracy(model,X_test_scaled, y_test)\n",
        "  cm = show_classification_report(model,X_test_scaled, y_test)\n",
        "  show_confusion_matrix(cm)"
      ],
      "metadata": {
        "id": "tb9-xJohcn5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "By17bAufUv0G"
      },
      "outputs": [],
      "source": [
        "def train(model,X_train_scaled, y_train,X_test_scaled, y_test):\n",
        "  model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
        "  #input 4\n",
        "  early_stop = EarlyStopping(monitor = 'val_accuracy', mode = 'max', patience=10, restore_best_weights=True)\n",
        "  history = model.fit(X_train_scaled, y_train, epochs=20, validation_data= (X_test_scaled, y_test))\n",
        "  return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izDnjRULwfY1"
      },
      "outputs": [],
      "source": [
        "def print_model_summary(model):\n",
        "  model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tfg5vTpVE-p"
      },
      "outputs": [],
      "source": [
        "def show_validation_accuracy(model,X_test_scaled, y_test):\n",
        "  model.evaluate(X_test_scaled, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08cLF29DwhNT"
      },
      "outputs": [],
      "source": [
        "def show_classification_report(model,X_test_scaled, y_test):\n",
        "  from sklearn.metrics import confusion_matrix , classification_report\n",
        "  import numpy as np\n",
        "  y_predict =  model.predict(X_test_scaled)\n",
        "  y_predict_classes = [np.argmax(element) for element in y_predict]\n",
        "  print(\"Classification Report: \\n\", classification_report(y_test, y_predict_classes))\n",
        "  cm = tf.math.confusion_matrix(labels=y_test,predictions=y_predict_classes)\n",
        "  return cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdeGrrGDwppc"
      },
      "outputs": [],
      "source": [
        "def show_confusion_matrix(cm):\n",
        "  import seaborn as sn\n",
        "  plt.figure(figsize = (10,8))\n",
        "  sn.heatmap(cm, annot=True, fmt='d')\n",
        "  plt.xlabel('Predicted')\n",
        "  plt.ylabel('Truth')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Learning_Process():\n",
        "  print(\"Learning...\")\n",
        "  total_images = getTotalImages()\n",
        "  print(total_images)\n",
        "  Tumor_images_dict,Tumor_labels_dict = defineTumourLabels()\n",
        "  print(\"Preprocessing...\")\n",
        "  X,y = preProcess(Tumor_images_dict,Tumor_labels_dict)\n",
        "  print(\"Preprocessing Done!\")\n",
        "  X_train_scaled,X_test_scaled, y_train, y_test = split(X,y)\n",
        "  model = struct_model()\n",
        "  print_model_summary(model)\n",
        "  history = train(model,X_train_scaled, y_train,X_test_scaled, y_test)\n",
        "  print(\"Learned!\")\n",
        "  print(\"Validation on process...\")\n",
        "  Validation_Process(model, X_test_scaled, y_test)\n"
      ],
      "metadata": {
        "id": "3o2sbR9EnHQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def names(number):\n",
        "    if number==0:\n",
        "        return 'Diagnosed with Glioma Tumor'\n",
        "    elif number==1:\n",
        "        return 'Diagnosed with Meningioma Tumor'\n",
        "    elif number==2:\n",
        "        return 'Diagnosed with No Tumor'\n",
        "    else:\n",
        "        return 'Diagnosed with Pituitary Tumor'"
      ],
      "metadata": {
        "id": "puW5pF0QcIh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Recognition_Process():\n",
        "  from matplotlib.pyplot import imshow\n",
        "  print(\"Recongnition...\")\n",
        "  print(\"Enter image path for recognition:\")\n",
        "  imgpath = input()\n",
        "  img = Image.open(imgpath)\n",
        "  x = np.array(img.resize((180,180)))\n",
        "  x = x.reshape(1,180,180,3)\n",
        "  res = model.predict_on_batch(x)\n",
        "  classification = np.where(res == np.amax(res))[1][0]\n",
        "  imshow(img)\n",
        "  print(str(res[0][classification]*100) + '% Confidence This Is ' + names(classification))"
      ],
      "metadata": {
        "id": "B9fqNq_gZrSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  print(\"Welcome to User Interaction Menu\")\n",
        "  print(\"--------------------------------\")\n",
        "  var = 2\n",
        "  while(var==1 or var==2):\n",
        "    print(\"1.Learning Phase\")\n",
        "    print(\"2.Recognition Phase\")\n",
        "    print(\"3.End Program\")\n",
        "    print(\"Enter an option:\")\n",
        "    var = input()\n",
        "    var = int(var)\n",
        "    if var == 1:\n",
        "      print(\"Starting learning...\")\n",
        "      Learning_Process()\n",
        "    elif var == 2:\n",
        "      Recognition_Process()"
      ],
      "metadata": {
        "id": "FX5ycDL4lOVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__==\"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "PZdKYAs4mwBJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of BrainMRI_Final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}